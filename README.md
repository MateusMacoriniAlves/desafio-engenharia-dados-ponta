# Desafio Engenharia de Dados - Ponta Agro

Este projeto consiste em um pipeline de ETL desenvolvido para o desafio tÃ©cnico da **Ponta Agro**, utilizando **Apache Airflow + Docker Compose**, com arquivos locais e integraÃ§Ã£o com API externa para realizar um processo ETL completo.

---

## âœ… Objetivo

Realizar um um pipeline de ETL com as seguintes fontes de dados:

- Um arquivo `.xlsx` com dados de preÃ§o do boi gordo (CEPEA)
- Uma API do Banco Central para obter o IPCA

### Etapas do processo:

1. ExtraÃ§Ã£o (arquivos e API)
2. Limpeza e imputaÃ§Ã£o de dados
3. Enriquecimento com IPCA
4. CÃ¡lculo de valor corrigido (valor real) e variaÃ§Ã£o percentual
5. Upsert no CSV final
6. Carga final em formato Parquet

---

## ğŸ“¦ Tecnologias e bibliotecas
- Apache Airflow
- pandas
- openpyxl
- requests
- pyarrow
- Docker + Docker Compose

---

## ğŸ“‚ Estrutura de diretÃ³rios
```
.
â”œâ”€â”€ dags/             # DAGs do Airflow
â”‚   â””â”€â”€ files/        # Scripts Python, funÃ§Ãµes auxiliares, etc.
â”œâ”€â”€ files/            # Arquivos de entrada para processamento
â”‚   â”œâ”€â”€ csv/          # ContÃ©m arquivos .csv
â”‚   â”œâ”€â”€ json/         # ContÃ©m arquivos .json
â”‚   â”œâ”€â”€ parquet/      # ContÃ©m arquivos .parquet
â”‚   â””â”€â”€ xlsx/         # ContÃ©m arquivos .xlsx
â”œâ”€â”€ config/           # ConfiguraÃ§Ãµes extras do projeto
â”œâ”€â”€ plugins/          # Plugins personalizados do Airflow
â”œâ”€â”€ logs/             # Logs das execuÃ§Ãµes
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
---

## ğŸš€ Como executar

### PrÃ©-requisitos

- Docker + Docker Compose
- Git

### Passos
- Clone o repositÃ³rio: ```git clone https://github.com/MateusMacoriniAlves/desafio-engenharia-dados-ponta.git```
- Construa os containers: ```docker compose build```
- Suba o ambiente: ```docker compose up``` (Pode levar alguns segundos)
- ApÃ³s subir o container, entre em: http://localhost:8080
- UsuÃ¡rio: ```airflow```
- Senha: ```airflow```

### PossÃ­veis erros
- Pode acontecer alguns erros com o WSL, em testes foi preciso executar esse comando ```mkdir -p ./dags ./logs ./plugins ./config                                                                                                                                                   â”€â”€(Wed,May21)â”€â”˜
echo -e "AIRFLOW_UID=$(id -u)" > .env``` antes do comando  ```docker compose up```
- Outro erro pode ser na configuraÃ§Ã£o do arquivo dockerfile. Na documentaÃ§Ã£o oficial tem um modelo, que foi utilizado nesse projeto. PorÃ©m pode ser necessÃ¡rio alterar o conteÃºdo para ```FROM apache/airflow:3.0.1

COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt ```

## ğŸ§ª Testes e execuÃ§Ã£o
- Verifique no painel se a DAG ```etl_boi_gordo``` existe.
- Execute a DAG manualmente para testar seu funcionamento

## ğŸ§¹ Parar e limpar o ambiente
- ```docker-compose down```
- ```docker-compose down --volumes --rmi all```

## ğŸ“Œ ObservaÃ§Ãµes
- Este projeto foi desenvolvido em Ubuntu 24.04 com Python 3.11.9 dentro dos containers.
- Um arquivo chamado api.py foi incluÃ­do na raiz do projeto para permitir testes fora do Airflow, caso desejado.
- Os diretÃ³rios como logs/, __pycache__/ e outros arquivos temporÃ¡rios estÃ£o devidamente ignorados no .gitignore.

## ğŸ‘¨â€ğŸ’» Autor
- Mateus Macorini Alves
- Linkedin: https://www.linkedin.com/in/mateus-macorini-alves-9398761a9/
- email: mmatmt1@gmail.com